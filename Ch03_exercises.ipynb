{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2210155",
   "metadata": {},
   "source": [
    "# Chapter 3. Linear Regression - Exercises\n",
    "\n",
    "Guillermo Reales - 2025-04-14\n",
    "\n",
    "## Conceptual\n",
    "\n",
    ">**1.** Describe the null hypotheses to which the p-values given in Table 3.4 correspond. Explain what conclusions you can draw based on these\n",
    "p-values. Your explanation should be phrased in terms of sales, TV, radio, and newspaper, rather than in terms of the coefficients of the linear model.\n",
    "\n",
    "**A:** The p-values in Table 3.4 (page 83 in the book) correspond to the null hypothesis that each of the 3 predictors included in the model (ie. money expended on `TV`, `radio`, and `newspaper` advertisement) has no effect on the outcome variable `sales`. Based on these p-values, we can conclude that, while keeping the other variables constant, expenditure on TV and radio (but not newspaper) advertising has a significant effect on sales.\n",
    "\n",
    ">**2.** Carefully explain the differences between the KNN classifier and KNN regression methods.\n",
    "\n",
    "**A:** While the underlying rationale is similar (ie. select a fixed number of neighbours and output a response based on their values), they apply to different problems. The KNN classifier is used to assign a point to a group, based on the group its K nearest neighbours belong to (therefore, the response variable is categorical). On the other hand, KNN regression is used to generate a prediction for a given point, taking the mean value of its KNN, hence when the response variable is continuous.\n",
    "\n",
    ">**3.** Suppose we have a data set with five predictors, $X_1 = GPA$, $X_2 = IQ$, $X_3 = Level$ (1 for College and 0 for High School), $X_4$ = Interaction between GPA and IQ, and $X_5$ = Interaction between GPA and Level. The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get $\\hat{\\beta_0} = 50$,$\\hat{\\beta_1} = 20$ , $\\hat{\\beta_2} = 0.07$, $\\hat{\\beta_3} = 35$, $\\hat{\\beta_4} = 0.01$, $\\hat{\\beta_5}= −10$ .\n",
    ">\n",
    ">(a) Which answer is correct, and why?\n",
    ">>i. For a fixed value of IQ and GPA, high school graduates earn\n",
    "more, on average, than college graduates.\n",
    ">>\n",
    ">>ii. For a fixed value of IQ and GPA, college graduates earn\n",
    "more, on average, than high school graduates.\n",
    ">>\n",
    ">>iii. For a fixed value of IQ and GPA, high school graduates earn more, on average, than college graduates provided that the\n",
    "GPA is high enough.\n",
    ">>\n",
    ">>iv. For a fixed value of IQ and GPA, college graduates earn\n",
    "more, on average, than high school graduates provided that\n",
    "the GPA is high enough.\n",
    "\n",
    "**A:** iii is the correct answer. The  $\\hat{\\beta_3}$ is positive and big (35), meaning college graduates earn more on average than high school students. However, there's a reasonably large interaction predictor $\\hat{\\beta_5}$ for Level and GPA with negative coefficient (-10), which would suggest iii that, if GPA is high enough (3.5+?), it may overcome the positive effect of being a college graduate.\n",
    "\n",
    ">(b) Predict the salary of a college graduate with IQ of 110 and a\n",
    "GPA of 4.0.\n",
    "\n",
    "**A:** 50 + 20*(4) + 0.07*(110) + 35*(1) + 0.01*(4*110) -10 * (4 * 1) = $137,100 \n",
    "\n",
    ">(c) True or false: Since the coefficient for the GPA/IQ interaction\n",
    "term is very small, there is very little evidence of an interaction\n",
    "effect. Justify your answer.\n",
    "\n",
    "**A:** False. We'd need to see the P-values to assert that the evidence for interaction is small, even if the absolute numbers look small. Also, IQ ranges around 120, meaning that even if the coefficient is small, the differences may still be noticeable.\n",
    "\n",
    "\n",
    ">4. I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression\n",
    "model to the data, as well as a separate cubic regression, i.e. $Y = \\hat{\\beta_0} + \\hat{\\beta_1}X + \\hat{\\beta_2}X^2 + \\hat{\\beta_0}X^3 + \\epsilon$.\n",
    ">\n",
    "> (a) Suppose that the true relationship between X and Y is linear, i.e. $Y = \\hat{\\beta_0} + \\hat{\\beta_1}X + \\epsilon$. Consider the training residual sum of squares (RSS) for the linear regression, and also the training\n",
    "RSS for the cubic regression. Would we expect one to be lower\n",
    "than the other, would we expect them to be the same, or is there\n",
    "not enough information to tell? Justify your answer.\n",
    "\n",
    "**A:** A cubic regression is more flexible, so it can adapt (ie. lower RSS) to training data better than a linear model. Without knowing anything else, I'd expect the training RSS to be lower for the cubic model.\n",
    "\n",
    ">(b) Answer (a) using test rather than training RSS.\n",
    "\n",
    "**A:** Here, as the true relationship is linear, I'd expect the linear model to have lower test RSS, as the cubic may capture noise from the training data that differs from the test data, increasing its RSS more than that of the linear model.\n",
    "\n",
    ">(c) Suppose that the true relationship between X and Y is not linear,\n",
    "but we don’t know how far it is from linear. Consider the training\n",
    "RSS for the linear regression, and also the training RSS for the\n",
    "cubic regression. Would we expect one to be lower than the\n",
    "other, would we expect them to be the same, or is there not\n",
    "enough information to tell? Justify your answer.\n",
    "\n",
    "**A:** For the reasons above, I'd expect the cubic model to have lower training RSS\n",
    "\n",
    ">(d) Answer (c) using test rather than training RSS.\n",
    "\n",
    "**A:** We don't have enough information to tell. If it's not too far from linear, the linear model should still win (ie lower RSS), but since we don't know this, it's hard to tell.\n",
    "\n",
    "\n",
    "[...]\n",
    "\n",
    "## Applied"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
